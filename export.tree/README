## Subjects
Participants (n=18) underwent two separate scanning sessions before training (ses-pre) and after training (ses-post) on the experimental task described below. Data was collected from consenting neurotypical subjects with standard inclusion/exclusion criteria (English speaking, right handed, no history of neurological or psychiatric illness) and the protocol was approved by the Carnegie Mellon University Institutional Review Board.

## Experimental Task
BOLD data were collected eyes open at rest. Participants were taught to execute specific single finger movements (index, middle, ring, little) that were recorded on a button glove in response to visual stimuli (stimuli/*.png) that were projected onto a screen. Participants learned a mapping of cue to finger press prior to the first imaging session. Task cuedSFM is cued Single Finger Movements. Each stimulus corresponded to one of 4 unique key presses and the mapping was identical across all participants. Participants had 1 second to initiate a unique finger press corresponding to the cue that appeared on the screen. The two fMRI sessions, ses-pre and ses-post, were collected before and after a 25 day training period, where participants either practiced a 32 element sequence (n=9 trained) or pseudorandomly ordered movements (n=9 control) for approximately 30 minutes each day. Group identity for each subject is available in /participants.tsv. Trial types in each of the events.tsv file correspond to individual key presses (2=index, 3=middle, 4=ring, 5=little). Additional details are available in the manuscript: Patrick Beukema, JÃ¶rn Diedrichsen, Timothy Verstynen. bioRxiv 255794; doi: https://doi.org/10.1101/255794 

## Data Acquisition
Data were acquired with a Siemens Verio 3T MRI Scanner and a 32-channel head coil. 6 separate runs for both the ses-pre and ses-post session were acquired. Each run consisted of acquiring 241 functional volumes (~8.03 min) of the same stimuli and key presses but in different orderings. All sequence protocol details for both the functional and anatomical images can be found in /sequence_protocols. Pydeface was used on all anatomical images to ensure de-identification of subjects. The code can be found at https://github.com/poldracklab/pydeface. 
